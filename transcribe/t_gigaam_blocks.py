#!/usr/bin/env python3# -*- coding: utf-8 -*-import osos.environ["HF_TOKEN"] = ""FFMPEG_BIN = r"C:\Tools\ffmpeg-8.0.1-full_build-shared\bin"if hasattr(os, 'add_dll_directory'):    if os.path.isdir(FFMPEG_BIN):        os.add_dll_directory(FFMPEG_BIN)        print(f"FFmpeg DLL path added: {FFMPEG_BIN}")    else:        print(f"Ошибка: папка {FFMPEG_BIN} не найдена!")else:    os.environ["PATH"] = FFMPEG_BIN + os.pathsep + os.environ.get("PATH", "")import argparseimport sysimport tempfileimport subprocessimport reimport loggingfrom pathlib import Pathfrom typing import Listimport torchfrom transformers import AutoModelfrom datetime import timedeltafrom pydantic import BaseModel, Field# Настройка логированияlogging.basicConfig(    level=logging.INFO,    format='%(asctime)s - %(levelname)s - %(message)s')logger = logging.getLogger(__name__)# ============================================================================# DTO Models (Pydantic)# ============================================================================class ChunkInfo(BaseModel):    """Информация об аудио-чанке"""    start_sec: float = Field(description="Начало чанка в секундах")    file_path: Path = Field(description="Путь к файлу чанка")class ChunkBoundary(BaseModel):    """Границы чанка"""    start_sec: float = Field(description="Начало в секундах")    end_sec: float = Field(description="Конец в секундах")class SentenceWithTimestamp(BaseModel):    """Предложение с временными метками"""    text: str = Field(description="Текст предложения")    start: float = Field(description="Начало в секундах")    end: float = Field(description="Конец в секундах")class TextBlock(BaseModel):    """Блок текста с временной меткой"""    start_sec: float = Field(description="Начало блока в секундах")    text: str = Field(description="Текст блока")class AudioChunkingResult(BaseModel):    """Результат нарезки аудио на чанки"""    chunks: List[ChunkInfo] = Field(description="Список чанков")    total_duration_sec: float = Field(description="Общая длительность аудио в секундах")# Настраиваемые параметрыMIN_PAUSE_SEC = 60            # минимальная пауза между предложениями для разрыва на новый блок (секунды)MAX_BLOCK_DURATION_SEC = 600  # максимальная длительность одного блока-абзаца (секунды)CHUNK_SEC = 20.0              # длина чанка для нарезки (сек) - не более 20 для GigaAMOVERLAP_SEC = 1.0             # перекрытие чанковdef seconds_to_hhmmss(total_sec: float) -> str:    """Конвертирует секунды в [HH:MM:SS]"""    td = timedelta(seconds=int(total_sec))    return f"[{str(td).zfill(8)}]"def is_video_file(file_path: Path) -> bool:    """Проверяет, является ли файл видео"""    video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.mpg', '.mpeg'}    return file_path.suffix.lower() in video_extensionsdef extract_audio_from_video(video_path: Path, output_dir: Path) -> Path:    """Извлекает аудио из видеофайла в WAV формат"""    audio_path = output_dir / f"{video_path.stem}_audio.wav"    logger.info(f"Извлечение аудио из видео: {video_path.name}")    cmd = [        "ffmpeg", "-y", "-i", str(video_path),        "-vn",  # Без видео        "-acodec", "pcm_s16le",  # PCM 16-bit        "-ar", "16000",  # Sample rate 16kHz        "-ac", "1",  # Mono        str(audio_path)    ]    logger.info(f"Команда: {' '.join(cmd)}")    result = subprocess.run(cmd, capture_output=True, text=True, encoding="utf-8", errors="replace")    if result.returncode != 0:        logger.error(f"Ошибка извлечения аудио: {result.stderr}")        raise RuntimeError(f"FFmpeg failed to extract audio from {video_path}")    logger.info(f"✓ Аудио извлечено: {audio_path.name} ({audio_path.stat().st_size / 1024 / 1024:.2f} MB)")    return audio_pathdef get_audio_duration_from_ffmpeg(input_path: Path) -> float:    """Извлекает длительность аудио через ffmpeg"""    logger.debug(f"Получение длительности аудио: {input_path}")    duration_cmd = ["ffmpeg", "-i", str(input_path), "-f", "null", "-"]    result = subprocess.run(        duration_cmd,        stderr=subprocess.PIPE,        text=True,        encoding="utf-8",        errors="replace"    )    for line in result.stderr.splitlines():        if "Duration:" in line:            dur_str = line.split("Duration:")[1].split(",")[0].strip()            h, m, s_ms = dur_str.split(":")            s, _ = s_ms.split(".")            total_sec = int(h) * 3600 + int(m) * 60 + int(s)            logger.info(f"Длительность аудио: {total_sec:.1f} сек")            return float(total_sec)    return 0.0def create_temp_directory_for_chunks() -> Path:    """Создает временную директорию для чанков"""    return Path(tempfile.mkdtemp(prefix="gigaam_chunks_"))def extract_audio_chunk_with_ffmpeg(        input_path: Path,        start_sec: float,        end_sec: float,        output_path: Path) -> None:    """Извлекает один чанк аудио через ffmpeg"""    cmd = [        "ffmpeg", "-y", "-i", str(input_path),        "-ss", str(start_sec),        "-t", str(end_sec - start_sec),        "-ar", "16000", "-ac", "1", "-c:a", "pcm_s16le",        str(output_path)    ]    subprocess.run(cmd, check=True, capture_output=True)def calculate_chunk_boundaries(        total_sec: float,        chunk_sec: float,        overlap_sec: float) -> List[ChunkBoundary]:    """Вычисляет границы всех чанков"""    boundaries = []    step = chunk_sec - overlap_sec    start_sec = 0.0    while start_sec < total_sec:        end_sec = min(start_sec + chunk_sec, total_sec)        if end_sec - start_sec < 5:            break        boundaries.append(ChunkBoundary(start_sec=start_sec, end_sec=end_sec))        start_sec += step    return boundariesdef generate_chunk_filename(start_sec: float, tmp_dir: Path) -> Path:    """Генерирует имя файла для чанка"""    return tmp_dir / f"chunk_{int(start_sec):06d}.wav"def cut_audio_to_chunks(        input_path: str,        chunk_sec: float = CHUNK_SEC,        overlap_sec: float = OVERLAP_SEC,) -> AudioChunkingResult:    """Нарезает аудио на чанки с перекрытием"""    input_path = Path(input_path)    logger.debug(f"Нарезка аудио на чанки: {input_path}")    total_sec = get_audio_duration_from_ffmpeg(input_path)    tmp_dir = create_temp_directory_for_chunks()    boundaries = calculate_chunk_boundaries(total_sec, chunk_sec, overlap_sec)    chunks = []    for boundary in boundaries:        chunk_file = generate_chunk_filename(boundary.start_sec, tmp_dir)        extract_audio_chunk_with_ffmpeg(input_path, boundary.start_sec, boundary.end_sec, chunk_file)        chunks.append(ChunkInfo(start_sec=boundary.start_sec, file_path=chunk_file))    logger.info(f"Создано {len(chunks)} чанков")    return AudioChunkingResult(chunks=chunks, total_duration_sec=total_sec)def split_into_sentences(text: str) -> list[str]:    """Разбивает текст на предложения по пунктуации"""    sentences = re.split(r'(?<=[.!?])\s+', text.strip())    return [s.strip() for s in sentences if s.strip()]def load_gigaam_model(revision: str, device: str) -> AutoModel:    """Загружает модель GigaAM-v3"""    logger.info(f"Загружаем GigaAM-v3 ({revision}) на {device.upper()}...")    model = AutoModel.from_pretrained(        "ai-sage/GigaAM-v3",        revision=revision,        trust_remote_code=True,    )    model.to(device)    model.eval()    logger.info("Модель загружена и готова к работе")    return modeldef transcribe_single_chunk(model: AutoModel, chunk_path: Path, chunk_start_sec: float) -> str:    """Транскрибирует один чанк аудио"""    # Проверяем размер файла    try:        chunk_size = chunk_path.stat().st_size        if chunk_size == 0:            logger.warning(f"Чанк {chunk_path.name} пустой (0 байт), пропускаем")            return ""    except OSError as e:        logger.error(f"Ошибка чтения файла {chunk_path.name}: {e}")        return ""    try:        with torch.inference_mode():            text = model.transcribe(str(chunk_path)).strip()        # Добавляем маркер [...] только для непустых чанков        if text:  # Только если есть текст            text_with_marker = text + " [...]"            logger.debug(f"Транскрибировано символов: {len(text)}")            return text_with_marker        else:            logger.debug("Пустой чанк, маркер не добавляется")            return text    except Exception as e:        logger.error(f"Ошибка транскрипции чанка {chunk_path.name}: {type(e).__name__} → {e}")        return ""def estimate_chunk_duration(chunk_path: Path) -> float:    """Грубая оценка длительности чанка по размеру файла"""    return chunk_path.stat().st_size / (16000 * 2)def calculate_sentence_timestamps(        sentences: list[str],        chunk_start_sec: float,        chunk_duration_sec: float) -> List[SentenceWithTimestamp]:    """Распределяет временные метки между предложениями чанка пропорционально их длине"""    if not sentences:        return []    total_chars = sum(len(s) for s in sentences)    if total_chars == 0:        return []    result = []    current_time = chunk_start_sec    for sent in sentences:        sent_duration = (len(sent) / total_chars) * chunk_duration_sec        result.append(SentenceWithTimestamp(            text=sent,            start=current_time,            end=current_time + sent_duration        ))        current_time += sent_duration    return resultdef remove_overlapping_duplicates(        sentences: List[SentenceWithTimestamp],        overlap_sec: float) -> List[SentenceWithTimestamp]:    """    Удаляет дублирующиеся предложения в зонах перекрытия чанков.    Алгоритм:    1. Группирует предложения по чанкам (по временным промежуткам)    2. В зоне перекрытия (последние overlap_sec секунд чанка) ищет похожие предложения    3. Удаляет дубликаты, оставляя предложение из более позднего чанка (более точное)    """    if not sentences:        return []    # Сортируем по времени начала    sorted_sentences = sorted(sentences, key=lambda s: s.start)    result = []    skip_until = -1.0  # Время, до которого пропускаем предложения (уже добавлены)    for i, sent in enumerate(sorted_sentences):        # Пропускаем предложения, которые уже были обработаны        if sent.start < skip_until:            logger.debug(f"Пропущен дубликат: [{sent.start:.1f}s] '{sent.text[:50]}...'")            continue        # Проверяем, есть ли похожее предложение в следующих N предложениях        # (в пределах зоны перекрытия)        is_duplicate = False        for j in range(i + 1, min(i + 10, len(sorted_sentences))):            next_sent = sorted_sentences[j]            # Если следующее предложение слишком далеко - прекращаем поиск            if next_sent.start > sent.start + overlap_sec * 2:                break            # Проверяем похожесть текста (простое сравнение без учёта регистра)            similarity = calculate_text_similarity(sent.text, next_sent.text)            if similarity > 0.8:  # 80% похожесть                logger.debug(                    f"Найден дубликат ({similarity:.0%}):\n"                    f"  [{sent.start:.1f}s] '{sent.text[:50]}...'\n"                    f"  [{next_sent.start:.1f}s] '{next_sent.text[:50]}...'"                )                is_duplicate = True                skip_until = next_sent.end                break        if not is_duplicate:            result.append(sent)    duplicates_removed = len(sentences) - len(result)    if duplicates_removed > 0:        logger.info(f"Удалено дубликатов в зонах перекрытия: {duplicates_removed}")    return resultdef calculate_text_similarity(text1: str, text2: str) -> float:    """    Вычисляет похожесть двух текстов (0.0 - 1.0).    Использует алгоритм Jaccard similarity для слов.    """    words1 = set(text1.lower().split())    words2 = set(text2.lower().split())    if not words1 or not words2:        return 0.0    intersection = words1.intersection(words2)    union = words1.union(words2)    return len(intersection) / len(union) if union else 0.0def transcribe_all_chunks(model: AutoModel, chunks: List[ChunkInfo]) -> List[SentenceWithTimestamp]:    """Транскрибирует все чанки и возвращает список предложений с временными метками"""    all_sentences = []    logger.info(f"Начинаем транскрипцию {len(chunks)} чанков")    for idx, chunk in enumerate(chunks, 1):        logger.info(f"→ Транскрипция чанка {idx}/{len(chunks)} (с {chunk.start_sec:.1f}с)...")        text = transcribe_single_chunk(model, chunk.file_path, chunk.start_sec)        sentences = split_into_sentences(text)        chunk_duration = estimate_chunk_duration(chunk.file_path)        timestamped_sentences = calculate_sentence_timestamps(            sentences,            chunk.start_sec,            chunk_duration        )        # Выводим распознанные предложения в консоль        if timestamped_sentences:            logger.info(f"  Распознано предложений: {len(timestamped_sentences)}")            for sent in timestamped_sentences:                timestamp = seconds_to_hhmmss(sent.start)                logger.info(f"  {timestamp} {sent.text}")        all_sentences.extend(timestamped_sentences)    logger.info(        f"\n{'=' * 80}\n"        f"Всего транскрибировано предложений: {len(all_sentences)}\n"        f"{'=' * 80}"    )    # Удаляем дубликаты в зонах перекрытия    all_sentences = remove_overlapping_duplicates(all_sentences, OVERLAP_SEC)    logger.info(f"После удаления дубликатов: {len(all_sentences)} предложений")    return all_sentencesdef should_start_new_block_by_pause(pause: float, current_block: List[SentenceWithTimestamp], min_pause_sec: float) -> bool:    """Проверяет, нужно ли начать новый блок из-за паузы"""    return pause >= min_pause_sec and len(current_block) > 0def should_start_new_block_by_duration(current_block: List[SentenceWithTimestamp], max_duration_sec: float) -> bool:    """Проверяет, нужно ли начать новый блок из-за превышения длительности"""    if len(current_block) == 0:        return False    block_duration = current_block[-1].end - current_block[0].start    return block_duration >= max_duration_secdef create_block_from_sentences(sentences: List[SentenceWithTimestamp]) -> TextBlock:    """Создает блок текста из списка предложений"""    block_text = " ".join(s.text for s in sentences)    block_start = sentences[0].start    return TextBlock(start_sec=block_start, text=block_text)def group_sentences_into_blocks(        sentences: List[SentenceWithTimestamp],        min_pause_sec: float,        max_duration_sec: float = MAX_BLOCK_DURATION_SEC) -> List[TextBlock]:    """Группирует предложения в блоки на основе пауз и максимальной длительности"""    logger.debug(        f"Группировка предложений в блоки:\n"        f"  - Предложений: {len(sentences)}\n"        f"  - Минимальная пауза: {min_pause_sec} сек\n"        f"  - Макс. длительность блока: {max_duration_sec} сек"    )    blocks = []    current_block = []    last_end = 0.0    for sent in sentences:        pause = sent.start - last_end        # Проверяем условия для создания нового блока        should_break_by_pause = should_start_new_block_by_pause(pause, current_block, min_pause_sec)        should_break_by_duration = should_start_new_block_by_duration(current_block, max_duration_sec)        if (should_break_by_pause or should_break_by_duration) and current_block:            block = create_block_from_sentences(current_block)            block_duration = current_block[-1].end - current_block[0].start            logger.debug(                f"Создан блок #{len(blocks)+1}: "                f"длительность={block_duration:.1f}с, "                f"предложений={len(current_block)}, "                f"причина={'пауза' if should_break_by_pause else 'длительность'}"            )            blocks.append(block)            current_block = []        current_block.append(sent)        last_end = sent.end    if current_block:        block = create_block_from_sentences(current_block)        block_duration = current_block[-1].end - current_block[0].start        logger.debug(            f"Создан блок #{len(blocks)+1}: "            f"длительность={block_duration:.1f}с, "            f"предложений={len(current_block)} (последний)"        )        blocks.append(block)    logger.info(f"Создано блоков: {len(blocks)}")    return blocksdef format_blocks_with_timestamps(blocks: List[TextBlock]) -> str:    """Форматирует блоки с временными метками"""    output_lines = []    for block in blocks:        timestamp = seconds_to_hhmmss(block.start_sec)        output_lines.append(f"{timestamp} {block.text}")    return "\n\n".join(output_lines)def cleanup_chunk_files(chunks: List[ChunkInfo]) -> None:    """Удаляет временные файлы чанков"""    for chunk in chunks:        if chunk.file_path.exists():            chunk.file_path.unlink()    if chunks:        tmp_dir = chunks[0].file_path.parent        if tmp_dir.exists():            tmp_dir.rmdir()def save_transcription_to_file(full_text: str, input_path: Path, revision: str) -> Path:    """    Сохраняет транскрипцию в текстовый файл.    Устанавливает дату модификации результата равной дате исходного файла.    """    # Генерируем имя файла: <имя>.gigaam-<revision>-blocks.txt    out_path = input_path.parent / f"{input_path.stem}.gigaam-{revision}-blocks.txt"    out_path.write_text(full_text, encoding="utf-8")    # Копируем время модификации исходного файла    original_mtime = input_path.stat().st_mtime    os.utime(out_path, (original_mtime, original_mtime))    logger.info(f"Результат сохранён: {out_path}")    return out_pathdef transcribe_file(        file_path: str,        revision: str = "e2e_rnnt",        device: str = "cuda" if torch.cuda.is_available() else "cpu",        chunk_sec: float = CHUNK_SEC,):    """Транскрибирует аудио/видеофайл с разбиением на блоки по паузам"""    input_path = Path(file_path)    logger.info(f"Начало транскрипции файла: {input_path.name}")    # Создаём временную директорию    tmp_dir = Path(tempfile.mkdtemp(prefix="gigaam_process_"))    audio_path = None    # Проверяем, является ли файл видео    is_video = is_video_file(input_path)    if is_video:        logger.info(f"Обнаружен видеофайл: {input_path.suffix}")        # Извлекаем аудио из видео        audio_path = extract_audio_from_video(input_path, tmp_dir)        process_path = str(audio_path)    else:        logger.info(f"Обнаружен аудиофайл: {input_path.suffix}")        process_path = file_path    model = load_gigaam_model(revision, device)    chunking_result = cut_audio_to_chunks(process_path, chunk_sec=chunk_sec)    all_sentences = transcribe_all_chunks(model, chunking_result.chunks)    blocks = group_sentences_into_blocks(all_sentences, MIN_PAUSE_SEC, MAX_BLOCK_DURATION_SEC)    full_text = format_blocks_with_timestamps(blocks)    cleanup_chunk_files(chunking_result.chunks)    # Удаляем извлечённое аудио из видео    if is_video and audio_path and audio_path.exists():        logger.debug(f"Удаляем извлечённое аудио: {audio_path.name}")        audio_path.unlink()    # Удаляем временную директорию    if tmp_dir.exists():        try:            tmp_dir.rmdir()        except:            pass    # Сохраняем с именем оригинального файла    output_path = save_transcription_to_file(full_text, input_path, revision)    logger.info(f"Транскрипция завершена: {output_path}")def parse_command_line_arguments() -> argparse.Namespace:    """Парсит аргументы командной строки"""    parser = argparse.ArgumentParser(description="GigaAM-v3 для длинных аудио с блоками по паузам")    parser.add_argument("input", nargs="+", help="файл или папка")    parser.add_argument("--revision", default="e2e_rnnt",                        choices=["e2e_rnnt", "e2e_ctc", "rnnt", "ctc", "ssl"])    parser.add_argument("--device", default="auto", choices=["auto", "cpu", "cuda"])    parser.add_argument("--chunk", type=float, default=CHUNK_SEC, help="длина чанка (сек)")    return parser.parse_args()def determine_device(device_arg: str) -> str:    """Определяет устройство для вычислений"""    if device_arg == "auto":        return "cuda" if torch.cuda.is_available() else "cpu"    return device_argdef collect_audio_files_from_paths(input_paths: list[str]) -> list[Path]:    """Собирает список аудио/видеофайлов из указанных путей"""    paths = []    audio_extensions = ("*.wav", "*.mp3", "*.m4a", "*.ogg", "*.flac", "*.aac")    video_extensions = ("*.mp4", "*.avi", "*.mkv", "*.mov", "*.wmv", "*.flv", "*.webm", "*.m4v", "*.mpg", "*.mpeg")    for p in input_paths:        path = Path(p).expanduser().resolve()        if path.is_dir():            # Ищем аудио файлы            for ext in audio_extensions:                paths.extend(path.rglob(ext))            # Ищем видео файлы            for ext in video_extensions:                paths.extend(path.rglob(ext))        elif path.is_file():            paths.append(path)    return pathsdef process_single_audio_file(path: Path, revision: str, device: str, chunk_sec: float) -> None:    """Обрабатывает один аудиофайл"""    print(f"\n{'═' * 80}")    print(f"Обрабатываем: {path}")    try:        transcribe_file(            str(path),            revision=revision,            device=device,            chunk_sec=chunk_sec,        )    except Exception as e:        print(f"Ошибка: {type(e).__name__} → {e}", file=sys.stderr)def process_audio_files(paths: list[Path], revision: str, device: str, chunk_sec: float) -> None:    """Обрабатывает список аудиофайлов"""    for path in sorted(paths):        process_single_audio_file(path, revision, device, chunk_sec)def main():    """Главная функция программы"""    args = parse_command_line_arguments()    device = determine_device(args.device)    paths = collect_audio_files_from_paths(args.input)    if not paths:        print("Не найдено аудио/видео файлов", file=sys.stderr)        sys.exit(1)    process_audio_files(paths, args.revision, device, args.chunk)if __name__ == "__main__":    sys.exit(main() or 0)